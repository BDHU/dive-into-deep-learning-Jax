{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edebcdb8",
   "metadata": {},
   "source": [
    "## Follow the [Guide](https://roberttlange.github.io/posts/2020/03/blog-post-10/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837fdd37",
   "metadata": {},
   "source": [
    "### vmap demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2cf65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, vmap, value_and_grad\n",
    "from jax import random\n",
    "import jax\n",
    "\n",
    "# Generate key which is used to generate random numbers\n",
    "key = random.PRNGKey(1)\n",
    "\n",
    "batch_dim = 32\n",
    "feature_dim = 100\n",
    "hidden_dim = 512\n",
    "\n",
    "# Generate a batch of inputs\n",
    "X = random.normal(key, (batch_dim, feature_dim))\n",
    "\n",
    "# Generate Gaussian weights and biases\n",
    "params_old = [random.normal(key, (hidden_dim, feature_dim)),\n",
    "          random.normal(key, (hidden_dim,))]\n",
    "\n",
    "W = params_old[0]\n",
    "print(W.shape)\n",
    "print(X.shape)\n",
    "b = params_old[1]\n",
    "print(b.shape)\n",
    "\n",
    "def ReLU(x):\n",
    "    \"\"\" Rectified Linear Unit (ReLU) activation function \"\"\"\n",
    "    return jnp.maximum(0, x)\n",
    "\n",
    "def ReLU_Layer(W, x, b):\n",
    "    return ReLU(jnp.dot(W, x) + b)\n",
    "\n",
    "def vmap_ReLU_Layer(func):\n",
    "    return jit( vmap(func, in_axes=(None, 0, None), out_axes=(0)) )\n",
    "print(\"dot product shape\")\n",
    "print(jnp.dot(W, X[0]).shape)\n",
    "print((jnp.dot(W, X[0]) + b).shape)\n",
    "\n",
    "relu = vmap_ReLU_Layer(ReLU_Layer)\n",
    "result = relu(W, X, b)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f611c876",
   "metadata": {},
   "outputs": [],
   "source": [
    "## test\n",
    "def relu_layer(params, x):\n",
    "    \"\"\" Simple ReLu layer for single sample \"\"\"\n",
    "    return ReLU(np.dot(params[0], x) + params[1])\n",
    "\n",
    "def batch_version_relu_layer(params, x):\n",
    "    \"\"\" Error prone batch version \"\"\"\n",
    "    return ReLU(np.dot(X, params[0].T) + params[1])\n",
    "\n",
    "def vmap_relu_layer(params, x):\n",
    "    \"\"\" vmap version of the ReLU layer \"\"\"\n",
    "    return jit(vmap(relu_layer, in_axes=(None, 0), out_axes=0))\n",
    "\n",
    "out = jnp.stack([relu_layer(params, X[i, :]) for i in range(X.shape[0])])\n",
    "out = batch_version_relu_layer(params, X)\n",
    "out = vmap_relu_layer(params, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a96fc5",
   "metadata": {},
   "source": [
    "### Jax [doc](https://jax.readthedocs.io/en/latest/notebooks/neural_network_with_tfds_data.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e03916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, vmap\n",
    "from jax import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858a14f6",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e336db84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function to randomly initialize weights and biases\n",
    "# for a dense neural network layer\n",
    "def random_layer_params(m, n, key, scale=1e-2):\n",
    "    w_key, b_key = random.split(key)\n",
    "    return scale * random.normal(w_key, (n, m)), scale * random.normal(b_key, (n,))\n",
    "\n",
    "# Initialize all layers for a fully-connected neural network with sizes \"sizes\"\n",
    "def init_network_params(sizes, key):\n",
    "    keys = random.split(key, len(sizes))\n",
    "    return [random_layer_params(m, n ,k) for m, n, k in zip(sizes[:-1], sizes[1:], keys)]\n",
    "\n",
    "layer_sizes = [784, 512, 512, 10]\n",
    "step_size = 0.01\n",
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "n_targets = 10\n",
    "keys = random.PRNGKey(0)\n",
    "params = init_network_params(layer_sizes, keys)\n",
    "print(layer_sizes[:-1])\n",
    "print(layer_sizes[1:])\n",
    "print(keys)\n",
    "\n",
    "for m, n, k in zip(layer_sizes[:-1], layer_sizes[1:], keys):\n",
    "    print(m)\n",
    "    print(n)\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44f41bb",
   "metadata": {},
   "source": [
    "## Auto-batching predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5aa967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def relu(x):\n",
    "    return jnp.maximum(0, x)\n",
    "\n",
    "def predict(params, img):\n",
    "    # per-example predictions\n",
    "    inputs = img\n",
    "    for w, b in params[:-1]:\n",
    "        outputs = relu(jnp.dot(w, inputs) + b)\n",
    "        inputs = outputs\n",
    "    \n",
    "    out_w, out_b = params[-1]\n",
    "    logits = jnp.dot(out_w, inputs) + out_b\n",
    "    return jax.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3ac1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This works on single examples\n",
    "random_flattened_img = random.normal(random.PRNGKey(1), (28 * 28, ))\n",
    "preds = predict(params, random_flattened_img)\n",
    "print(preds)\n",
    "print(jnp.sum(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0831e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This works on single examples\n",
    "random_flattened_image = random.normal(random.PRNGKey(1), (28 * 28,))\n",
    "preds = predict(params, random_flattened_image)\n",
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38979224",
   "metadata": {},
   "source": [
    "### Doesn't work with batched inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14e4075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doesn't work with a batch\n",
    "random_flattened_images = random.normal(random.PRNGKey(1), (10, 28 * 28))\n",
    "try:\n",
    "  preds = predict(params, random_flattened_images)\n",
    "except TypeError:\n",
    "  print('Invalid shapes!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07289484",
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_predict = jax.jit(jax.vmap(predict, in_axes=(None, 0), out_axes=0))\n",
    "batched_inputs = random.normal(random.PRNGKey(1), (12, 28 * 28))\n",
    "print(batched_inputs.shape)\n",
    "print(batched_inputs[:].shape)\n",
    "print(batched_inputs[:, None].shape)\n",
    "batched_pred = batched_predict(params, batched_inputs)\n",
    "print(np.array([1,2]).shape)\n",
    "print(jnp.arange(2).shape)\n",
    "print(batched_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79732e9",
   "metadata": {},
   "source": [
    "## Utility and loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3d3bdd",
   "metadata": {},
   "source": [
    "## Data Loading with `tensorflow/datasets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d15616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(x, k, dtype=jnp.float32):\n",
    "    \"\"\"Create a one-hot encoding of x of size k.\"\"\"\n",
    "    return jnp.array(x[:, None] == jnp.arange(k), dtype)\n",
    "\n",
    "def accuracy(params, images, targets):\n",
    "    target_class = jnp.argmax(targets, axis=1)\n",
    "    predicted_class = jnp.argmax(batched_predict(params, images), axis=1)\n",
    "    return jnp.mean(predicted_class == target_class)\n",
    "\n",
    "def loss(params, images, targets):\n",
    "    preds = batched_predict(params, images)\n",
    "    return -jnp.mean(preds * targets)\n",
    "\n",
    "# my own loss function\n",
    "def cross_entropy_loss(output, target):\n",
    "     return -jnp.log(output[target])\n",
    "\n",
    "def batched_cross_entropy_loss(cross_entropy_loss=cross_entropy_loss):\n",
    "    return jit(vmap(cross_entropy_loss, in_axes=(0, 0), out_axes=(0)))\n",
    "\n",
    "my_loss = batched_cross_entropy_loss()\n",
    "test_in = jnp.array([[0.1, 0.9], [0.5, 0.5]])\n",
    "test_target = jnp.array([0, 1])\n",
    "test_out = my_loss(test_in, test_target)\n",
    "print(test_out)\n",
    "\n",
    "def myloss_func(params, images, targets):\n",
    "    preds = batched_predict(params, images)\n",
    "    print(preds.shape)\n",
    "    print(targets.shape)\n",
    "    return my_loss(preds, targets)\n",
    "\n",
    "@jit\n",
    "def update(params, x, y):\n",
    "    grads = grad(loss)(params, x, y)\n",
    "    return [(w - step_size * dw, b - step_size * db)\n",
    "          for (w, b), (dw, db) in zip(params, grads)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2015906e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Ensure TF does not see GPU and grab all GPU memory.\n",
    "tf.config.set_visible_devices([], device_type='GPU')\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "data_dir = '/tmp/tfds'\n",
    "\n",
    "# Fetch full datasets for evaluation\n",
    "# tfds.load returns tf.Tensors (or tf.data.Datasets if batch_size != -1)\n",
    "# You can convert them to NumPy arrays (or iterables of NumPy arrays) with tfds.dataset_as_numpy\n",
    "mnist_data, info = tfds.load(name=\"mnist\", batch_size=-1, data_dir=data_dir, with_info=True)\n",
    "mnist_data = tfds.as_numpy(mnist_data)\n",
    "train_data, test_data = mnist_data['train'], mnist_data['test']\n",
    "num_labels = info.features['label'].num_classes\n",
    "h, w, c = info.features['image'].shape\n",
    "num_pixels = h * w * c\n",
    "\n",
    "# Full train set\n",
    "train_images, train_labels = train_data['image'], train_data['label']\n",
    "train_images = jnp.reshape(train_images, (len(train_images), num_pixels))\n",
    "train_labels = one_hot(train_labels, num_labels)\n",
    "\n",
    "# Full test set\n",
    "test_images, test_labels = test_data['image'], test_data['label']\n",
    "test_images = jnp.reshape(test_images, (len(test_images), num_pixels))\n",
    "test_labels = one_hot(test_labels, num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09c7129",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train:', train_images.shape, train_labels.shape)\n",
    "print('Test:', test_images.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bb8f3c",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76ee471",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def get_train_batches():\n",
    "  # as_supervised=True gives us the (image, label) as a tuple instead of a dict\n",
    "  ds = tfds.load(name='mnist', split='train', as_supervised=True, data_dir=data_dir)\n",
    "  # You can build up an arbitrary tf.data input pipeline\n",
    "  ds = ds.batch(batch_size).prefetch(1)\n",
    "  # tfds.dataset_as_numpy converts the tf.data.Dataset into an iterable of NumPy arrays\n",
    "  return tfds.as_numpy(ds)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  start_time = time.time()\n",
    "  for x, y in get_train_batches():\n",
    "    x = jnp.reshape(x, (len(x), num_pixels))\n",
    "    y = one_hot(y, num_labels)\n",
    "    params = update(params, x, y)\n",
    "  epoch_time = time.time() - start_time\n",
    "\n",
    "  train_acc = accuracy(params, train_images, train_labels)\n",
    "  test_acc = accuracy(params, test_images, test_labels)\n",
    "  print(\"Epoch {} in {:0.2f} sec\".format(epoch, epoch_time))\n",
    "  print(\"Training set accuracy {}\".format(train_acc))\n",
    "  print(\"Test set accuracy {}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11296bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
